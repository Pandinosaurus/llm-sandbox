# llm-sandbox

[![Release](https://img.shields.io/github/v/release/vndee/llm-sandbox)](https://img.shields.io/github/v/release/vndee/llm-sandbox)
[![Build status](https://img.shields.io/github/actions/workflow/status/vndee/llm-sandbox/main.yml?branch=main)](https://github.com/vndee/llm-sandbox/actions/workflows/main.yml?query=branch%3Amain)
[![Commit activity](https://img.shields.io/github/commit-activity/m/vndee/llm-sandbox)](https://img.shields.io/github/commit-activity/m/vndee/llm-sandbox)
[![License](https://img.shields.io/github/license/vndee/llm-sandbox)](https://img.shields.io/github/license/vndee/llm-sandbox)

LLM Sandbox is a lightweight and portable sandbox environment designed to run large language model (LLM) generated code in a safe and isolated manner using containers.

## Documentation

- [Getting Started](getting-started.md) - Quick start guide and basic usage
- [Configuration](configuration.md) - Configuration options and environment setup
- [Artifact Extraction](artifact-extraction.md) - Automatic plot and visualization capture
- [Tutorials](tutorials.md) - Step-by-step tutorials and practical examples
- [Extending Artifact Extraction](extending-artifact-extraction.md) - Developer guide for adding new language support
- [Security Guide](security-guide.md) - Security features and best practices
- [API Reference](modules.md) - Complete API documentation
- [Contributing](contributing.md) - How to contribute to the project
